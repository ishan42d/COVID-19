{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coronavirus Tracker "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "##### The following datasets have been recorded from: \n",
    " * https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data\n",
    " * https://www.worldometers.info/coronavirus/\n",
    "\n",
    "These datasets are updated on a daily basis by the Johns Hopkins Univerity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from fbprophet import Prophet\n",
    "import pycountry\n",
    "import plotly.express as px\n",
    "from collections import namedtuple\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pathlib\n",
    "from datetime import date,timedelta\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reading JHU database\n",
    "url1 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "df_r = pd.read_csv(url1, index_col=0)\n",
    "\n",
    "url2 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "df_c = pd.read_csv(url2, index_col=0)\n",
    "\n",
    "url3 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "df_d = pd.read_csv(url3, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.reset_index(inplace=True)\n",
    "df_c.reset_index(inplace=True)\n",
    "df_d.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming cols\n",
    "df_c.rename(columns={'Country/Region':'country','Province/State':'province_state'}, inplace=True)\n",
    "df_r.rename(columns={'Country/Region':'country','Province/State':'province_state'}, inplace=True)\n",
    "df_d.rename(columns={'Country/Region':'country','Province/State':'province_state'}, inplace=True)\n",
    "#Renaming country names\n",
    "df_r['country'] = np.where(df_r.country == 'Korea, South','South Korea',df_r['country'])\n",
    "df_d['country'] = np.where(df_d.country == 'Korea, South','South Korea',df_d['country'])\n",
    "df_c['country'] = np.where(df_c.country == 'Korea, South','South Korea',df_c['country'])\n",
    "#Dropping diamond pricess and other cruises\n",
    "df_r = df_r[~(df_r.country.isin([\"Diamond Princess\",\"MS Zaandam\"]))]\n",
    "df_d = df_d[~(df_d.country.isin([\"Diamond Princess\",\"MS Zaandam\"]))]\n",
    "df_c = df_c[~(df_c.country.isin([\"Diamond Princess\",\"MS Zaandam\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_melt=df_c_ge.copy()\n",
    "df_d_melt=df_d_ge.copy()\n",
    "df_r_melt=df_r_ge.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_ge.drop(columns=['province_state','Lat','Long'],inplace=True,axis=1)\n",
    "df_c_ge.rename(columns={df_c_ge.columns[-1]:\"current_day_confirmed\",df_c_ge.columns[-2]: \"prev_day_confirmed\" }, inplace = True)\n",
    "df_c_ge['prev_day_diff_confrimed'] = df_c_ge['current_day_confirmed'] - df_c_ge['prev_day_confirmed']\n",
    "df_c_1 = df_c_ge[['country','prev_day_confirmed','current_day_confirmed','prev_day_diff_confrimed']]\n",
    "df_c_grpd = df_c_1.groupby('country').sum()\n",
    "\n",
    "df_r_ge.drop(columns=['province_state','Lat','Long'],inplace=True,axis=1)\n",
    "df_r_ge.rename(columns={df_r_ge.columns[-1]:\"current_day_recover\",df_r_ge.columns[-2]: \"prev_day_recover\" }, inplace = True)\n",
    "df_r_ge['prev_day_diff_recover'] = df_r_ge['current_day_recover'] - df_r_ge['prev_day_recover']\n",
    "df_r_1 = df_r_ge[['country','prev_day_recover','current_day_recover','prev_day_diff_recover']]\n",
    "df_r_grpd = df_r_1.groupby('country').sum()\n",
    "\n",
    "df_d_ge.drop(columns=['province_state','Lat','Long'],inplace=True,axis=1)\n",
    "df_d_ge.rename(columns={df_d_ge.columns[-1]:\"current_day_death\",df_d_ge.columns[-2]: \"prev_day_death\" }, inplace = True)\n",
    "df_d_ge['prev_day_diff_death'] = df_d_ge['current_day_death'] - df_d_ge['prev_day_death']\n",
    "df_d_1 = df_d_ge[['country','prev_day_death','current_day_death','prev_day_diff_death']]\n",
    "df_d_grpd = df_d_1.groupby('country').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged1 = pd.concat([df_c_grpd, df_r_grpd], axis=1)\n",
    "df_merged_global = pd.concat([df_merged1,df_d_grpd],axis=1)\n",
    "df_merged_global.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the region column as well\n",
    "who_region = pd.read_csv('who_region.csv')\n",
    "who_region.rename(columns={'Country/Region':'country','WHO Region':'region'},inplace= True)\n",
    "df_merged_global_who_region = df_merged_global[['country','prev_day_confirmed','current_day_confirmed','prev_day_diff_confrimed','prev_day_recover',\n",
    "         'current_day_recover','prev_day_diff_recover','prev_day_death','current_day_death','prev_day_diff_death']].merge(who_region[['country','region']],on='country',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed = df_c_melt.melt(id_vars=['country','province_state','Lat','Long'],\n",
    "                    var_name='Date',\n",
    "                    value_name='total_confrimed')\n",
    "df_recover = df_r_melt.melt(id_vars=['country','province_state','Lat','Long'],\n",
    "                    var_name='Date',\n",
    "                    value_name='total_recover')\n",
    "df_deaths = df_d_melt.melt(id_vars=['country','province_state','Lat','Long'],\n",
    "                    var_name='Date',\n",
    "                    value_name='total_deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>province_state</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>total_confrimed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.2027</td>\n",
       "      <td>17.8739</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-38.4161</td>\n",
       "      <td>-63.6167</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Australian Capital Territory</td>\n",
       "      <td>-35.4735</td>\n",
       "      <td>149.0124</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country                province_state      Lat      Long     Date  \\\n",
       "0    Albania                           NaN  41.1533   20.1683  1/22/20   \n",
       "1    Algeria                           NaN  28.0339    1.6596  1/22/20   \n",
       "2     Angola                           NaN -11.2027   17.8739  1/22/20   \n",
       "3  Argentina                           NaN -38.4161  -63.6167  1/22/20   \n",
       "4  Australia  Australian Capital Territory -35.4735  149.0124  1/22/20   \n",
       "\n",
       "   total_confrimed  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confirmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_confirmed['key'] = df_confirmed['province_state'].astype(str)+'-'+df_confirmed['country'].astype(str)+'-'+df_confirmed['Date'].astype(str)\n",
    "\n",
    "df_recover['key'] = df_recover['province_state'].astype(str) + '-'+df_recover['country'].astype(str)+'-'+df_recover['Date'].astype(str)\n",
    "\n",
    "df_deaths['key'] = df_deaths['province_state'].astype(str) + '-'+ df_deaths['country'].astype(str) + '-' + df_deaths['Date'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1= df_confirmed[['province_state','country','Lat','Long','Date','total_confrimed','key']].merge(df_deaths[['total_deaths','key']], on='key', how='left')\n",
    "df_2 = df_1[['province_state','country','Lat','Long','Date','total_confrimed','total_deaths','key']].merge(df_recover[['total_recover','key']],on='key',how='left')\n",
    "df_global = df_2.drop(columns=['key'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>total_confrimed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.2027</td>\n",
       "      <td>17.8739</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>-38.4161</td>\n",
       "      <td>-63.6167</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australian Capital Territory</td>\n",
       "      <td>Australia</td>\n",
       "      <td>-35.4735</td>\n",
       "      <td>149.0124</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 province_state    country      Lat      Long     Date  \\\n",
       "0                           NaN    Albania  41.1533   20.1683  1/22/20   \n",
       "1                           NaN    Algeria  28.0339    1.6596  1/22/20   \n",
       "2                           NaN     Angola -11.2027   17.8739  1/22/20   \n",
       "3                           NaN  Argentina -38.4161  -63.6167  1/22/20   \n",
       "4  Australian Capital Territory  Australia -35.4735  149.0124  1/22/20   \n",
       "\n",
       "   total_confrimed  total_deaths  total_recover  \n",
       "0                0             0            0.0  \n",
       "1                0             0            0.0  \n",
       "2                0             0            0.0  \n",
       "3                0             0            0.0  \n",
       "4                0             0            0.0  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_global.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global.total_confrimed.fillna(0,inplace=True)\n",
    "df_global.total_deaths.fillna(0,inplace=True)\n",
    "df_global.total_recover.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the region column as well\n",
    "df_global = df_global[['province_state','country','Lat','Long','Date','total_confrimed','total_deaths','total_recover']].merge(who_region[['country','region']],on='country',how='left')\n",
    "df_global.drop(['Lat','Long'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global.to_excel(r'raw_global_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global.to_excel(r'raw_global_data_for_graphs.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# India Analysis - State Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "##### The following datasets have been recorded from: \n",
    " * https://github.com/kalyaniuniversity/COVID-19-Datasets\n",
    " * https://www.worldometers.info/coronavirus/\n",
    " * https://www.mohfw.gov.in/\n",
    "\n",
    "These datasets are updated on a daily basis by the Kalyani Univerity and the Indian Govt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = 'https://raw.githubusercontent.com/kalyaniuniversity/COVID-19-Datasets/master/India%20Statewise%20Recovery%20Cases/COVID19_INDIA_STATEWISE_TIME_SERIES_RECOVERY.csv'\n",
    "df_rec_india = pd.read_csv(url4, index_col=0)\n",
    "\n",
    "url5 = 'https://raw.githubusercontent.com/kalyaniuniversity/COVID-19-Datasets/master/India%20Statewise%20Confirmed%20Cases/COVID19_INDIA_STATEWISE_TIME_SERIES_CONFIRMED.csv'\n",
    "df_con_india = pd.read_csv(url5, index_col=0)\n",
    "\n",
    "url6 = 'https://raw.githubusercontent.com/kalyaniuniversity/COVID-19-Datasets/master/India%20Statewise%20Death%20Cases/COVID19_INDIA_STATEWISE_TIME_SERIES_DEATH.csv'\n",
    "\n",
    "df_dea_india = pd.read_csv(url6, index_col=0)\n",
    "\n",
    "df_rec_india.reset_index(inplace=True)\n",
    "df_con_india.reset_index(inplace=True)\n",
    "df_dea_india.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_India_melt=df_con_india.copy()\n",
    "df_d_India_melt=df_dea_india.copy()\n",
    "df_r_India_melt=df_rec_india.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed\n",
    "df_con_india.drop(columns=['CODE','LATITUDE','LONGITUDE','PER CAPITA INCOME (INR)','AVERAGE TEMPERATURE (°C)'],inplace=True,axis=1)\n",
    "df_con_india.rename(columns={'STATE/UT':'STATE_UT',df_con_india.columns[-1]:\"current_day_confirmed\",df_con_india.columns[-2]: \"prev_day_confirmed\" }, inplace = True)\n",
    "df_con_india['prev_day_diff_confrimed'] = df_con_india['current_day_confirmed'] - df_con_india['prev_day_confirmed']\n",
    "df_con_india1 = df_con_india[['STATE_UT','POPULATION','prev_day_confirmed','current_day_confirmed','prev_day_diff_confrimed']]\n",
    "#Recover\n",
    "df_rec_india.drop(columns=['CODE','LATITUDE','LONGITUDE','PER CAPITA INCOME (INR)','AVERAGE TEMPERATURE (°C)'],inplace=True,axis=1)\n",
    "df_rec_india.rename(columns={'STATE/UT':'STATE_UT',df_rec_india.columns[-1]:\"current_day_recover\",df_rec_india.columns[-2]: \"prev_day_recover\" }, inplace = True)\n",
    "df_rec_india['prev_day_diff_recover'] = df_rec_india['current_day_recover'] - df_rec_india['prev_day_recover']\n",
    "df_rec_india1 = df_rec_india[['STATE_UT','prev_day_recover','current_day_recover','prev_day_diff_recover']]\n",
    "#Death\n",
    "df_dea_india.drop(columns=['CODE','LATITUDE','LONGITUDE','PER CAPITA INCOME (INR) ','AVERAGE TEMPERATURE (°C)'],inplace=True,axis=1)\n",
    "df_dea_india.rename(columns={'STATE/UT':'STATE_UT',df_dea_india.columns[-1]:\"current_day_deaths\",df_dea_india.columns[-2]: \"prev_day_deaths\" }, inplace = True)\n",
    "df_dea_india['prev_day_diff_deaths'] = df_dea_india['current_day_deaths'] - df_dea_india['prev_day_deaths']\n",
    "df_dea_india1 = df_dea_india[['STATE_UT','prev_day_deaths','current_day_deaths','prev_day_diff_deaths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged1_India = df_con_india1.merge(df_rec_india1,on='STATE_UT',how='left')\n",
    "df_merged_India = df_merged1_India.merge(df_dea_india1,on='STATE_UT',how='left')\n",
    "df_merged_India.rename(columns={'STATE_UT':'States_UT'},inplace=True)\n",
    "df_merged_India = df_merged_India[~(df_merged_India.States_UT.isin([\"Total\",\"Unassigned State\",\"Daman and Diu\"]))]\n",
    "# df_merged_India.set_index('STATE_UT',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed_india = df_c_India_melt.melt(id_vars=['STATE/UT','CODE','LATITUDE','LONGITUDE','PER CAPITA INCOME (INR)','POPULATION','AVERAGE TEMPERATURE (°C)'],\n",
    "                    var_name='Date',\n",
    "                    value_name='total_confirmed')\n",
    "df_deaths_india = df_d_India_melt.melt(id_vars=['STATE/UT','CODE','LATITUDE','LONGITUDE','PER CAPITA INCOME (INR) ','POPULATION','AVERAGE TEMPERATURE (°C)'],\n",
    "                    var_name='Date',\n",
    "                    value_name='total_deaths')\n",
    "df_recover_india = df_r_India_melt.melt(id_vars=['STATE/UT','CODE','LATITUDE','LONGITUDE','PER CAPITA INCOME (INR)','POPULATION','AVERAGE TEMPERATURE (°C)'],\n",
    "                    var_name='Date',\n",
    "                    value_name='total_recovered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['AVERAGE TEMPERATURE (°C)','PER CAPITA INCOME (INR)','LATITUDE','LONGITUDE','POPULATION']\n",
    "df_confirmed_india.drop(col,axis=1,inplace=True)\n",
    "df_recover_india.drop(col,axis=1,inplace=True)\n",
    "col1 = ['AVERAGE TEMPERATURE (°C)','PER CAPITA INCOME (INR) ','LATITUDE','LONGITUDE','POPULATION']\n",
    "df_deaths_india.drop(col1,axis=1,inplace=True)\n",
    "\n",
    "df_confirmed_india['key'] = df_confirmed_india['STATE/UT'].astype(str)+'-'+df_confirmed_india['CODE'].astype(str)+'-'+df_confirmed_india['Date'].astype(str)\n",
    "df_recover_india['key'] = df_recover_india['STATE/UT'].astype(str) + '-'+df_recover_india['CODE'].astype(str)+'-'+df_recover_india['Date'].astype(str)\n",
    "df_deaths_india['key'] = df_deaths_india['STATE/UT'].astype(str) + '-'+ df_deaths_india['CODE'].astype(str) + '-' + df_deaths_india['Date'].astype(str)\n",
    "\n",
    "df_1_India= df_confirmed_india[['STATE/UT','CODE','Date','total_confirmed','key']].merge(df_deaths_india[['total_deaths','key']], on='key', how='left')\n",
    "df_2_India = df_1_India[['STATE/UT','CODE','Date','total_confirmed','total_deaths','key']].merge(df_recover_india[['total_recovered','key']],on='key',how='left')\n",
    "df_India = df_2_India.drop(columns=['key'])\n",
    "df_India.rename(columns={'STATE/UT':'STATE_UT'},inplace=True)\n",
    "df_India = df_India[~(df_India.STATE_UT.isin([\"Total\",\"Unassigned State\",\"Daman and Diu\"]))]\n",
    "df_India.set_index('STATE_UT',inplace=True)\n",
    "df_India.to_excel(r'raw_data_India.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>Date</th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recovered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_UT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andaman and Nicobar Islands</th>\n",
       "      <td>an</td>\n",
       "      <td>1/30/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andhra Pradesh</th>\n",
       "      <td>ap</td>\n",
       "      <td>1/30/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arunachal Pradesh</th>\n",
       "      <td>ar</td>\n",
       "      <td>1/30/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assam</th>\n",
       "      <td>as</td>\n",
       "      <td>1/30/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bihar</th>\n",
       "      <td>br</td>\n",
       "      <td>1/30/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            CODE       Date  total_confirmed  total_deaths  \\\n",
       "STATE_UT                                                                     \n",
       "Andaman and Nicobar Islands   an  1/30/2020                0             0   \n",
       "Andhra Pradesh                ap  1/30/2020                0             0   \n",
       "Arunachal Pradesh             ar  1/30/2020                0             0   \n",
       "Assam                         as  1/30/2020                0             0   \n",
       "Bihar                         br  1/30/2020                0             0   \n",
       "\n",
       "                             total_recovered  \n",
       "STATE_UT                                      \n",
       "Andaman and Nicobar Islands                0  \n",
       "Andhra Pradesh                             0  \n",
       "Arunachal Pradesh                          0  \n",
       "Assam                                      0  \n",
       "Bihar                                      0  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_India.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State level data from MOHFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from pandas.io.json import json_normalize\n",
    "url = 'https://www.mohfw.gov.in/data/datanew.json'\n",
    "res = requests.get(url)\n",
    "with open(\"data.json\", \"w\") as f:\n",
    "    json.dump(res.json(), f)\n",
    "df_in = pd.read_json('data.json', orient='columns')\n",
    "df_in.drop(['state_code','sno'],inplace=True, axis=1)\n",
    "df_in['state_name'] = df_in['state_name'].replace({'Telengana': 'Telangana','Dadra and Nagar Haveli and Daman and Diu':'Dadra and Nagar Haveli'})\n",
    "df_in = df_in[df_in.state_name != '']\n",
    "df_in.rename(columns={'state_name':'States_UT','active': 'ActiveCases','cured':'Recovered','death':'Deaths',\n",
    "                     'positive':'Confirmed'},inplace=True)\n",
    "df_in[\"POPULATION\"] = df_in[\"POPULATION\"].str.replace(',', '').astype(float).astype(int)\n",
    "df_in.drop('state',inplace=True,axis=1)\n",
    "df_in.set_index('States_UT',inplace=True)\n",
    "df_in.to_excel(r'India_state_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ******************************************** End of data prep for India ***********************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USA Analysis - State Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following datasets have been recorded from: \n",
    " * https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data\n",
    " * https://www.worldometers.info/coronavirus/\n",
    "\n",
    "These datasets are updated on a daily basis by the Johns Hopkins Univerity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "url8 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "df_c_US = pd.read_csv(url8, index_col=0)\n",
    "\n",
    "url9 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
    "df_d_US = pd.read_csv(url9, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_US.reset_index(inplace=True)\n",
    "df_d_US.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_US = df_c_US[~(df_c_US.Province_State.isin([\"Hawaii\",\"Alaska\",\"American Samoa\", \"Diamond Princess\",\"Grand Princess\",\"Guam\",\"Northern Mariana Islands\",\"Virgin Islands\"]))]\n",
    "df_d_US = df_d_US[~(df_d_US.Province_State.isin([\"Hawaii\",\"Alaska\",\"American Samoa\", \"Diamond Princess\",\"Grand Princess\",\"Guam\",\"Northern Mariana Islands\",\"Virgin Islands\"]))]\n",
    "df_c_US_melt=df_c_US.copy()\n",
    "df_d_US_melt=df_d_US.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_d_US.drop(columns=['UID','iso2','iso3','code3','FIPS','Admin2','Country_Region','Combined_Key'],inplace=True,axis=1)\n",
    "df_c_US.drop(columns=['UID','iso2','iso3','code3','FIPS','Admin2','Country_Region','Combined_Key','Lat','Long_'],inplace=True,axis=1)\n",
    "df_c_US.rename(columns={df_c_US.columns[-1]:\"current_day_confirmed\",df_c_US.columns[-2]: \"prev_day_confirmed\" }, inplace = True)\n",
    "df_c_US['prev_day_diff_confrimed'] = df_c_US['current_day_confirmed'] - df_c_US['prev_day_confirmed']\n",
    "df_c_US_1 = df_c_US[['Province_State','prev_day_confirmed','current_day_confirmed','prev_day_diff_confrimed']]\n",
    "df_c_US_grpd = df_c_US_1.groupby('Province_State').sum()\n",
    "# df_d_US.drop(columns=['UID','iso2','iso3','code3','FIPS','Admin2','Country_Region','Combined_Key'],inplace=True,axis=1)\n",
    "df_d_US.drop(columns=['UID','iso2','iso3','code3','FIPS','Admin2','Country_Region','Combined_Key','Lat','Long_'],inplace=True,axis=1)\n",
    "df_d_US.rename(columns={df_d_US.columns[-1]:\"current_day_death\",df_d_US.columns[-2]: \"prev_day_death\" }, inplace = True)\n",
    "df_d_US['prev_day_diff_death'] = df_d_US['current_day_death'] - df_d_US['prev_day_death']\n",
    "df_d_US_1 = df_d_US[['Province_State','prev_day_death','current_day_death','prev_day_diff_death']]\n",
    "df_d_US_grpd = df_d_US_1.groupby('Province_State').sum()\n",
    "df_merged1_US = pd.concat([df_c_US_grpd, df_d_US_grpd], axis=1)\n",
    "df_merged1_US.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed_US = df_c_US_melt.melt(id_vars=['UID','iso2','iso3','code3','FIPS','Admin2','Province_State','Country_Region','Lat','Long_','Combined_Key'],\n",
    "                    var_name='Date',\n",
    "                    value_name='total_confirmed')\n",
    "df_deaths_US = df_d_US_melt.melt(id_vars=['UID','iso2','iso3','code3','FIPS','Admin2','Province_State','Country_Region','Lat','Long_','Combined_Key','Population'],\n",
    "                    var_name='Date',\n",
    "                    value_name='total_deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_US = ['UID','iso2','iso3','code3','FIPS','Admin2','Lat','Long_','Combined_Key']\n",
    "col_US1 = ['UID','iso2','iso3','code3','FIPS','Admin2','Lat','Long_','Combined_Key','Population']\n",
    "df_confirmed_US.drop(col_US,axis=1,inplace=True)\n",
    "df_deaths_US.drop(col_US1,axis=1,inplace=True)\n",
    "df_deaths_US = df_deaths_US[~(df_deaths_US.Province_State.isin([\"Puerto Rico\"]))]\n",
    "df_confirmed_US = df_confirmed_US[~(df_confirmed_US.Province_State.isin([\"Puerto Rico\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths_US.set_index('Province_State',inplace=True)\n",
    "df_confirmed_US.set_index('Province_State',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed_US.to_excel(r'confirmed_US.xlsx')\n",
    "df_deaths_US.to_excel(r'deaths_US.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url_us = 'https://www.worldometers.info/coronavirus/country/us/'\n",
    "html_page=requests.get(url_us).text\n",
    "soup = BeautifulSoup(html_page,'lxml')\n",
    "get_table = soup.find(\"table\",id=\"usa_table_countries_today\")\n",
    "get_table_data =get_table.tbody.find_all(\"tr\")\n",
    "dic={}\n",
    "for i in range(len(get_table_data)):\n",
    "    try:\n",
    "        key = get_table_data[i].find_all(\"a\",href=True)[0].string\n",
    "    except:\n",
    "        key = get_table_data[i].find_all(\"td\")[0].string # there is not href inside the td text\n",
    "    \n",
    "    values = [j.string for j in get_table_data[i].find_all('td')]\n",
    "    dic[key] =values\n",
    "    \n",
    "column_names_US = [\"Total_Cases\",\"New_Cases\",\"Total_Deaths\",\"New_Deaths\",\"Total_Recovered\",\"ActiveCases\",\"TotCases1MPop\",\"Deaths1MPop\",\"TotalTests\",\"Tests1MPop\"]\n",
    "US_state_data = pd.DataFrame(dic).iloc[1:,:].T.iloc[:,:10]\n",
    "US_state_data.columns=column_names_US\n",
    "US_state_data.reset_index(inplace = True)\n",
    "US_state_data.rename(columns={'index': 'USA State'},inplace=True)\n",
    "US_state_data = US_state_data.replace({'\\n+':''}, regex=True)\n",
    "US_state_data['New_Cases'] =US_state_data['New_Cases'].str.replace('+','') \n",
    "US_state_data['New_Deaths'] =US_state_data['New_Deaths'].str.replace('+','') \n",
    "US_state_data.rename(columns={'USA State':'Province_State'},inplace=True)\n",
    "US_state_data['Province_State'] = US_state_data['Province_State'].replace({'District Of Columbia': 'District of Columbia'})\n",
    "US_state_data.drop(US_state_data.index[0],axis=0,inplace=True)\n",
    "US_state_semi_final = US_state_data.merge(df_merged1_US,on='Province_State',how='left')\n",
    "US_state_semi_final.to_excel(r'US_state_semi_final.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# China - Overall and statewise and curr prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the global data to get the daily count for China\n",
    "df_china= df_global[df_global.country == 'China']\n",
    "df_china.reset_index(inplace=True)\n",
    "df_china.drop(['index','region'],axis=1,inplace=True)\n",
    "df_china.to_excel(r'raw_data_china.xlsx')\n",
    "#******************************************************************\n",
    "#CALCULATING CURR PREV DAY DIFF FOR CHINA\n",
    "url17 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "df_rc = pd.read_csv(url1, index_col=0)\n",
    "url18 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "df_cc = pd.read_csv(url2, index_col=0)\n",
    "url9 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "df_dc = pd.read_csv(url3, index_col=0)\n",
    "df_rc.reset_index(inplace=True)\n",
    "df_cc.reset_index(inplace=True)\n",
    "df_dc.reset_index(inplace=True)\n",
    "#Renaming cols\n",
    "df_cc.rename(columns={'Country/Region':'country','Province/State':'province_state'}, inplace=True)\n",
    "df_rc.rename(columns={'Country/Region':'country','Province/State':'province_state'}, inplace=True)\n",
    "df_dc.rename(columns={'Country/Region':'country','Province/State':'province_state'}, inplace=True)\n",
    "#Taking only the data for china\n",
    "df_china_r= df_rc[df_rc.country == 'China']\n",
    "df_china_d= df_dc[df_dc.country == 'China']\n",
    "df_china_c= df_cc[df_cc.country == 'China']\n",
    "#confirmed\n",
    "df_china_c.drop(columns=['Lat','Long'],inplace=True,axis=1)\n",
    "df_china_c.rename(columns={df_china_c.columns[-1]:\"current_day_confirmed\",df_china_c.columns[-2]: \"prev_day_confirmed\"}, inplace = True)\n",
    "df_china_c['newConfirmedcases'] = df_china_c['current_day_confirmed'] - df_china_c['prev_day_confirmed']\n",
    "df_china_c_1 = df_china_c[['country','province_state','prev_day_confirmed','current_day_confirmed','newConfirmedcases']]\n",
    "df_china_confirmed_grpd = df_china_c_1.groupby('province_state').sum()\n",
    "#recovered\n",
    "df_china_r.drop(columns=['Lat','Long'],inplace=True,axis=1)\n",
    "df_china_r.rename(columns={df_china_r.columns[-1]:\"current_day_recover\",df_china_r.columns[-2]: \"prev_day_recover\"}, inplace = True)\n",
    "df_china_r['newRecoveredcases'] = df_china_r['current_day_recover'] - df_china_r['prev_day_recover']\n",
    "df_china_r_1 = df_china_r[['country','province_state','prev_day_recover','current_day_recover','newRecoveredcases']]\n",
    "df_china_recover_grpd = df_china_r_1.groupby('province_state').sum()\n",
    "#deaths\n",
    "df_china_d.drop(columns=['Lat','Long'],inplace=True,axis=1)\n",
    "df_china_d.rename(columns={df_china_d.columns[-1]:\"current_day_death\",df_china_d.columns[-2]: \"prev_day_death\"}, inplace = True)\n",
    "df_china_d['newDeaths'] = df_china_d['current_day_death'] - df_china_d['prev_day_death']\n",
    "df_china_d_1 = df_china_d[['country','province_state','prev_day_death','current_day_death','newDeaths']]\n",
    "df_china_death_grpd = df_china_d_1.groupby('province_state').sum()\n",
    "#Merge\n",
    "df_merged_china = pd.concat([df_china_confirmed_grpd, df_china_recover_grpd], axis=1)\n",
    "df_merged_china1 = pd.concat([df_merged_china,df_china_death_grpd],axis=1)\n",
    "df_merged_china1['country'] = 'China'\n",
    "df_merged_china1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brazil Overall \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_labels = {'AC': 'Acre','AL': 'Alagoas','AM': 'Amazonas','AP': 'Amapá','BA': 'Bahia',\n",
    "                'CE': 'Ceará','DF': 'Distrito Federal','ES': 'Espírito Santo','GO': 'Goiás','MA': 'Maranhão',\n",
    "                'MG': 'Minas Gerais','MS': 'Mato Grosso do Sul','MT': 'Mato Grosso','PA': 'Pará','PB': 'Paraíba',\n",
    "                'PE': 'Pernambuco','PI': 'Piauí','PR': 'Paraná','RJ': 'Rio de Janeiro','RN': 'Rio Grande do Norte',\n",
    "                'RO': 'Rondônia','RR': 'Roraima','RS': 'Rio Grande do Sul','SC': 'Santa Catarinao','SE': 'Sergipe',\n",
    "                'SP':'São Paulo','TO':'Tocantins'}\n",
    "s = pd.Series(state_labels, name='State')\n",
    "s1 = pd.DataFrame(s)\n",
    "s2 = s1.reset_index()\n",
    "s3 = s2.set_index('index')['State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brazil daily data statewise\n",
    "url20 = 'https://raw.githubusercontent.com/wcota/covid19br/master/cases-brazil-states.csv'\n",
    "df_brazil = pd.read_csv(url20, index_col=0)\n",
    "df_brazil.reset_index(inplace=True)\n",
    "df_brazil.fillna(0, inplace=True)\n",
    "df_brazil1=df_brazil[['date','country','state','deaths','recovered','totalCases']]\n",
    "df_brazil1 = df_brazil1[~(df_brazil1.state.isin([\"TOTAL\"]))]\n",
    "df_brazil1['state'] = df_brazil1['state'].replace(s3)\n",
    "df_brazil1.to_excel('raw_data_Brazil.xlsx')\n",
    "df_brazil2 =df_brazil1.copy()\n",
    "#specific datasets\n",
    "df_brazil1_confirmed = df_brazil2[['date','country','state','totalCases']]\n",
    "df_brazil1_recover = df_brazil2[['date','country','state','recovered']]\n",
    "df_brazil1_deaths = df_brazil2[['date','country','state','deaths']]\n",
    "#inplace\n",
    "df_brazil1_confirmed.reset_index(inplace=True)\n",
    "df_brazil1_recover.reset_index(inplace=True)\n",
    "df_brazil1_deaths.reset_index(inplace=True)\n",
    "#drop\n",
    "df_brazil1_deaths.drop('index',inplace=True,axis=1)\n",
    "df_brazil1_recover.drop('index',inplace=True,axis=1)\n",
    "df_brazil1_confirmed.drop('index',inplace=True,axis=1)\n",
    "\n",
    "df_brazil1_deaths_pivot = df_brazil1_deaths.pivot_table(index=['country','state'],columns=['date'],values='deaths')\n",
    "df_brazil1_deaths_pivot.reset_index(inplace=True)\n",
    "\n",
    "df_brazil1_confirmed_pivot = df_brazil1_confirmed.pivot_table(index=['country','state'],columns=['date'],values='totalCases')\n",
    "df_brazil1_confirmed_pivot.reset_index(inplace=True)\n",
    "\n",
    "df_brazil1_recover_pivot = df_brazil1_recover.pivot_table(index=['country','state'],columns=['date'],values='recovered')\n",
    "df_brazil1_recover_pivot.reset_index(inplace=True)\n",
    "\n",
    "df_brazil1_confirmed_pivot.rename(columns={df_brazil1_deaths_pivot.columns[-1]:\"current_day_confirmed\",df_brazil1_confirmed_pivot.columns[-2]: \"prev_day_confirmed\" }, inplace = True)\n",
    "df_brazil1_confirmed_pivot['prev_day_diff_confrimed'] = df_brazil1_confirmed_pivot['current_day_confirmed'] - df_brazil1_confirmed_pivot['prev_day_confirmed']\n",
    "df_brazil1_confirmed_pivot1 = df_brazil1_confirmed_pivot[['country','state','prev_day_confirmed','current_day_confirmed','prev_day_diff_confrimed']]\n",
    "df_brazil_confirmed_grpd = df_brazil1_confirmed_pivot1.groupby('state').sum()\n",
    "\n",
    "df_brazil1_recover_pivot.rename(columns={df_brazil1_recover_pivot.columns[-1]:\"current_day_recover\",df_brazil1_recover_pivot.columns[-2]: \"prev_day_recover\" }, inplace = True)\n",
    "df_brazil1_recover_pivot['prev_day_diff_recover'] = df_brazil1_recover_pivot['current_day_recover'] - df_brazil1_recover_pivot['prev_day_recover']\n",
    "df_brazil1_recover_pivot1 = df_brazil1_recover_pivot[['country','state','prev_day_recover','current_day_recover','prev_day_diff_recover']]\n",
    "df_brazil_recover_grpd = df_brazil1_recover_pivot1.groupby('state').sum()\n",
    "\n",
    "df_brazil1_deaths_pivot.rename(columns={df_brazil1_deaths_pivot.columns[-1]:\"current_day_death\",df_brazil1_deaths_pivot.columns[-2]: \"prev_day_death\" }, inplace = True)\n",
    "df_brazil1_deaths_pivot['prev_day_diff_death'] = df_brazil1_deaths_pivot['current_day_death'] - df_brazil1_deaths_pivot['prev_day_death']\n",
    "df_brazil1_deaths_pivot1 = df_brazil1_deaths_pivot[['country','state','prev_day_death','current_day_death','prev_day_diff_death']]\n",
    "df_brazil_deaths_grpd = df_brazil1_deaths_pivot1.groupby('state').sum()\n",
    "#merge all tables \n",
    "df_merged1_Brazil = df_brazil_confirmed_grpd.merge(df_brazil_recover_grpd,on='state',how='left')\n",
    "df_merged_Brazil = df_merged1_Brazil.merge(df_brazil_deaths_grpd,on='state',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brazil statewise data load - aggregated\n",
    "url21 = 'https://raw.githubusercontent.com/wcota/covid19br/master/cases-brazil-total.csv'\n",
    "df_brazil_agg = pd.read_csv(url21, index_col=0)\n",
    "df_brazil_agg['state'] = df_brazil_agg['state'].replace(s3)\n",
    "df_brazil_agg.reset_index(inplace=True)\n",
    "df_brazil_agg.drop(df_brazil_agg.index[0],axis=0,inplace=True)\n",
    "df_brazil_agg1 = df_brazil_agg.merge(df_merged_Brazil,on='state',how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
